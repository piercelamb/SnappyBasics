17/05/11 12:43:50.357 PDT run-main-0<tid=0x2b> INFO snappystore: 
---------------------------------------------------------------------------

  Copyright (c) 2016 SnappyData, Inc. All rights reserved.

  Licensed under the Apache License, Version 2.0 (the "License"); you
  may not use this file except in compliance with the License. You
  may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
  implied. See the License for the specific language governing
  permissions and limitations under the License. See accompanying
  LICENSE file.

---------------------------------------------------------------------------
Java version:   1.5.4 amogh 031017 2017-03-10 17:51:17 +0530 javac 1.8.0_66
Native version: gemfirexd native code unavailable
Source revision: 392bbf24c28530a624b81e1f95232b6da6688e53
Source repository: branch-1.5.4
Running on: Pierces-MacBook-Pro.local/10.1.10.186, 8 cpu(s), x86_64 Mac OS X 10.11.2
Process ID: 43011
User: plamb
Current dir: /Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics
Home dir: /Users/plamb
Command Line Parameters:
  -Xms1024m
  -Xmx1024m
  -XX:ReservedCodeCacheSize=128m
  -XX:MaxMetaspaceSize=256m
Class Path:
  /usr/local/Cellar/sbt/0.13.9/libexec/sbt-launch.jar
Library Path:
  /Users/plamb/Library/Java/Extensions
  /Library/Java/Extensions
  /Network/Library/Java/Extensions
  /System/Library/Java/Extensions
  /usr/lib/java
  .
System Properties:
    awt.toolkit = sun.lwawt.macosx.LWCToolkit
    file.encoding = UTF-8
    file.encoding.pkg = sun.io
    file.separator = /
    ftp.nonProxyHosts = local|*.local|169.254/16|*.169.254/16
    gemfire.log-file = gemfirexd-interface.log
    gemfirexd.log-file = gemfirexd-interface.log
    gopherProxySet = false
    http.nonProxyHosts = local|*.local|169.254/16|*.169.254/16
    java.awt.graphicsenv = sun.awt.CGraphicsEnvironment
    java.awt.printerjob = sun.lwawt.macosx.CPrinterJob
    java.class.version = 52.0
    java.endorsed.dirs = /Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/endorsed
    java.ext.dirs = /Users/plamb/Library/Java/Extensions:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/ext:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java
    java.home = /Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre
    java.io.tmpdir = /var/folders/w1/v_m_9hp567qdv77k1rrglw_c0000gn/T/
    java.runtime.name = Java(TM) SE Runtime Environment
    java.runtime.version = 1.8.0_72-b15
    java.specification.name = Java Platform API Specification
    java.specification.vendor = Oracle Corporation
    java.specification.version = 1.8
    java.vendor = Oracle Corporation
    java.vendor.url = http://java.oracle.com/
    java.vendor.url.bug = http://bugreport.sun.com/bugreport/
    java.version = 1.8.0_72
    java.vm.info = mixed mode
    java.vm.name = Java HotSpot(TM) 64-Bit Server VM
    java.vm.specification.name = Java Virtual Machine Specification
    java.vm.specification.vendor = Oracle Corporation
    java.vm.specification.version = 1.8
    java.vm.vendor = Oracle Corporation
    java.vm.version = 25.72-b15
    jline.esc.timeout = 0
    jline.shutdownhook = false
    jna.loaded = true
    jna.platform.library.path = /usr/lib:/usr/lib
    jnidispatch.path = /var/folders/w1/v_m_9hp567qdv77k1rrglw_c0000gn/T/jna-106748474/jna2177863878725673851.tmp
    line.separator = 

    os.version = 10.11.2
    p2p.useSSL = false
    path.separator = :
    socksNonProxyHosts = local|*.local|169.254/16|*.169.254/16
    sun.arch.data.model = 64
    sun.boot.class.path = /Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/classes
    sun.boot.library.path = /Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib
    sun.cpu.endian = little
    sun.cpu.isalist = 
    sun.font.fontmanager = sun.font.CFontManager
    sun.io.unicode.encoding = UnicodeBig
    sun.java.command = /usr/local/Cellar/sbt/0.13.9/libexec/sbt-launch.jar run
    sun.java.launcher = SUN_STANDARD
    sun.jnu.encoding = UTF-8
    sun.management.compiler = HotSpot 64-Bit Tiered Compilers
    sun.nio.ch.bugLevel = 
    sun.os.patch.level = unknown
    user.country = US
    user.language = en
    user.timezone = America/Los_Angeles
---------------------------------------------------------------------------

17/05/11 12:43:50.357 PDT run-main-0<tid=0x2b> INFO snappystore: Renamed old log file to "gemfirexd-interface-02-01.log".
17/05/11 12:43:50.359 PDT run-main-0<tid=0x2b> INFO snappystore: Startup Configuration:
 ### GemFire Properties defined with system property ###
log-file=gemfirexd-interface.log
### GemFire Properties defined with api ###
mcast-port=0
### GemFire Properties using default values ###
ack-severe-alert-threshold=0
ack-wait-threshold=15
archive-disk-space-limit=0
archive-file-size-limit=0
async-distribution-timeout=0
async-max-queue-size=8
async-queue-timeout=60000
bind-address=
cache-xml-file=cache.xml
conflate-events=server
conserve-sockets=true
delta-propagation=true
deploy-working-dir=.
disable-auto-reconnect=false
disable-tcp=false
distributed-system-id=-1
durable-client-id=
durable-client-timeout=300
enable-network-partition-detection=false
enable-time-statistics=false
enforce-unique-host=false
groups=
jmx-manager=false
jmx-manager-access-file=
jmx-manager-bind-address=
jmx-manager-hostname-for-clients=
jmx-manager-http-port=7070
jmx-manager-password-file=
jmx-manager-port=1099
jmx-manager-ssl=false
jmx-manager-ssl-ciphers=any
jmx-manager-ssl-protocols=any
jmx-manager-ssl-require-authentication=true
jmx-manager-start=false
jmx-manager-update-rate=2000
locators=
lock-memory=false
log-disk-space-limit=0
log-file-size-limit=0
log-level=config
max-num-reconnect-tries=3
max-wait-time-reconnect=60000
mcast-address=239.192.81.1
mcast-flow-control=1048576, 0.25, 5000
mcast-recv-buffer-size=1048576
mcast-send-buffer-size=65535
mcast-ttl=32
member-timeout=5000
membership-port-range=1024-65535
memcached-port=0
memcached-protocol=ASCII
name=
off-heap-memory-size=
redundancy-zone=
remote-locators=
remove-unresponsive-client=false
roles=
security-=
security-client-accessor=
security-client-accessor-pp=
security-client-auth-init=
security-client-authenticator=
security-client-dhalgo=
security-log-file=
security-log-level=config
security-peer-auth-init=
security-peer-authenticator=
security-peer-verifymember-timeout=1000
server-bind-address=
socket-buffer-size=32768
socket-lease-time=60000
ssl-ciphers=any
ssl-enabled=false
ssl-protocols=any
ssl-require-authentication=true
start-locator=
statistic-archive-file=
statistic-sample-rate=1000
statistic-sampling-enabled=true
tcp-port=0
udp-fragment-size=60000
udp-recv-buffer-size=1048576
udp-send-buffer-size=65535
user-command-packages=

17/05/11 12:43:50.360 PDT run-main-0<tid=0x2b> INFO snappystore: Running in local mode since mcast-port was 0 and locators was empty.
17/05/11 12:43:50.440 PDT Thread-15 StatSampler<tid=0x77> INFO snappystore: Disabling statistic archival.
17/05/11 12:43:50.627 PDT run-main-0<tid=0x2b> INFO snappystore: Initializing region _monitoringRegion_10.1.10.186<v-1>0
17/05/11 12:43:50.696 PDT run-main-0<tid=0x2b> INFO snappystore: GemFire Cache successfully created.
17/05/11 12:43:50.703 PDT run-main-0<tid=0x2b> INFO snappystore: GfxdHeapThreshold: Query Cancellation Thread Started with query cancellation interval 100ms
17/05/11 12:43:50.722 PDT run-main-0<tid=0x2b> INFO snappystore: GemFire Cache successfully booted with 
--- file properties ---
--- EMPTY ---
--- boot connection properties ---
 gemfirexd.access="memstore"
 gemfirexd.authentication.required="false"
 gemfirexd.database-object="com.pivotal.gemfirexd.internal.engine.db.FabricDatabase@4a019817"
 gemfirexd.engineType="2"
 gemfirexd.serviceLocale="en_US"
 gemfirexd.serviceProtocol="com.pivotal.gemfirexd.internal.database.Database"
 mcast-port="0"
 route-query="false"
--- end --

17/05/11 12:43:50.722 PDT run-main-0<tid=0x2b> INFO snappystore: TraceFabricServiceBoot: GemFireStore: booted with persist-indexes=true
17/05/11 12:43:50.727 PDT run-main-0<tid=0x2b> INFO snappystore: This JVM is setup with SnappyData datastore role.
17/05/11 12:43:50.774 PDT run-main-0<tid=0x2b> INFO snappystore: Locked disk store GFXD-DEFAULT-DISKSTORE for exclusive access in directory: /Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/.
17/05/11 12:43:50.805 PDT run-main-0<tid=0x2b> INFO snappystore: Recovered disk store GFXD-DEFAULT-DISKSTORE with unique id 9563dc3b-a6ae-4b2a-977d-5e6abb70f5e5
17/05/11 12:43:50.814 PDT run-main-0<tid=0x2b> INFO snappystore: Recovering oplog#2 /Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./BACKUPGFXD-DEFAULT-DISKSTORE_2.drf for disk store GFXD-DEFAULT-DISKSTORE.
17/05/11 12:43:50.814 PDT run-main-0<tid=0x2b> INFO snappystore: Recovering oplog#1 /Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./BACKUPGFXD-DEFAULT-DISKSTORE_1.drf for disk store GFXD-DEFAULT-DISKSTORE.
17/05/11 12:43:50.816 PDT run-main-0<tid=0x2b> INFO snappystore: Recovering oplog#2 /Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./BACKUPGFXD-DEFAULT-DISKSTORE_2.crf for disk store GFXD-DEFAULT-DISKSTORE.
17/05/11 12:43:50.818 PDT run-main-0<tid=0x2b> INFO snappystore: Recovering oplog#1 /Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./BACKUPGFXD-DEFAULT-DISKSTORE_1.krf for disk store GFXD-DEFAULT-DISKSTORE.
17/05/11 12:43:50.832 PDT run-main-0<tid=0x2b> INFO snappystore: recovery oplog load took 18 ms
17/05/11 12:43:50.833 PDT Oplog Delete Task<tid=0x82> INFO snappystore: Deleted oplog#2 crf for disk store GFXD-DEFAULT-DISKSTORE.
17/05/11 12:43:50.834 PDT Oplog Delete Task<tid=0x82> INFO snappystore: Deleted oplog#2 drf for disk store GFXD-DEFAULT-DISKSTORE.
17/05/11 12:43:51.051 PDT run-main-0<tid=0x2b> INFO snappystore: Created oplog#3 drf for disk store GFXD-DEFAULT-DISKSTORE.
17/05/11 12:43:52.398 PDT run-main-0<tid=0x2b> INFO snappystore: Created oplog#3 crf for disk store GFXD-DEFAULT-DISKSTORE.
17/05/11 12:43:52.410 PDT run-main-0<tid=0x2b> INFO snappystore: recoverOplogs oplog: oplog#2 parent: GFXD-DEFAULT-DISKSTORE, needskrf: true
17/05/11 12:43:52.410 PDT run-main-0<tid=0x2b> INFO snappystore: createKrfAsync called for oplog: oplog#2, parent: GFXD-DEFAULT-DISKSTORE
17/05/11 12:43:52.411 PDT run-main-0<tid=0x2b> INFO snappystore: recovery region initialization took 1,579 ms
17/05/11 12:43:52.416 PDT run-main-0<tid=0x2b> INFO snappystore: Locked disk store GFXD-DD-DISKSTORE for exclusive access in directory: ./datadictionary
17/05/11 12:43:52.427 PDT run-main-0<tid=0x2b> INFO snappystore: Recovered disk store GFXD-DD-DISKSTORE with unique id d3cdc1da-d856-4b7a-8372-42c5938100ca
17/05/11 12:43:52.428 PDT run-main-0<tid=0x2b> INFO snappystore: Recovering oplog#2 /Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./datadictionary/BACKUPGFXD-DD-DISKSTORE_2.drf for disk store GFXD-DD-DISKSTORE.
17/05/11 12:43:52.428 PDT run-main-0<tid=0x2b> INFO snappystore: Recovering oplog#2 /Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./datadictionary/BACKUPGFXD-DD-DISKSTORE_2.crf for disk store GFXD-DD-DISKSTORE.
17/05/11 12:43:52.428 PDT run-main-0<tid=0x2b> INFO snappystore: recovery oplog load took 0 ms
17/05/11 12:43:52.429 PDT Oplog Delete Task<tid=0x85> INFO snappystore: Deleted oplog#2 crf for disk store GFXD-DD-DISKSTORE.
17/05/11 12:43:52.429 PDT Oplog Delete Task<tid=0x85> INFO snappystore: Deleted oplog#2 drf for disk store GFXD-DD-DISKSTORE.
17/05/11 12:43:52.443 PDT run-main-0<tid=0x2b> INFO snappystore: Created oplog#3 drf for disk store GFXD-DD-DISKSTORE.
17/05/11 12:43:52.461 PDT run-main-0<tid=0x2b> INFO snappystore: Created oplog#3 crf for disk store GFXD-DD-DISKSTORE.
17/05/11 12:43:52.465 PDT run-main-0<tid=0x2b> INFO snappystore: recoverOplogs oplog: oplog#2 parent: GFXD-DD-DISKSTORE, needskrf: true
17/05/11 12:43:52.465 PDT run-main-0<tid=0x2b> INFO snappystore: createKrfAsync called for oplog: oplog#2, parent: GFXD-DD-DISKSTORE
17/05/11 12:43:52.465 PDT run-main-0<tid=0x2b> INFO snappystore: recovery region initialization took 36 ms
17/05/11 12:43:52.479 PDT run-main-0<tid=0x2b> WARN snappystore: Creating persistent region GFXD_PdxTypes, but enable-network-partition-detection is set to false. Running with network partition detection disabled can lead to an unrecoverable system in the event of a network split.
17/05/11 12:43:52.479 PDT run-main-0<tid=0x2b> INFO snappystore: Initializing region GFXD_PdxTypes
17/05/11 12:43:52.480 PDT run-main-0<tid=0x2b> INFO snappystore: Region /GFXD_PdxTypes recovered from the local disk. Old persistent ID: /10.1.10.186:/Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./datadictionary created at timestamp 1494531610800 version 0 diskStoreId d3cdc1da-d856-4b7a-8372-42c5938100ca name , new persistent ID /10.1.10.186:/Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./datadictionary created at timestamp 1494531832479 version 0 diskStoreId d3cdc1da-d856-4b7a-8372-42c5938100ca name 
17/05/11 12:43:52.483 PDT run-main-0<tid=0x2b> INFO snappystore: Initializing region _DDL_STMTS_META_REGION
17/05/11 12:43:52.484 PDT run-main-0<tid=0x2b> INFO snappystore: Region /_DDL_STMTS_META_REGION recovered from the local disk. Old persistent ID: /10.1.10.186:/Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./datadictionary created at timestamp 1494531610804 version 0 diskStoreId d3cdc1da-d856-4b7a-8372-42c5938100ca name , new persistent ID /10.1.10.186:/Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./datadictionary created at timestamp 1494531832483 version 0 diskStoreId d3cdc1da-d856-4b7a-8372-42c5938100ca name 
17/05/11 12:43:52.510 PDT run-main-0<tid=0x2b> INFO snappystore: Initializing region __PR
17/05/11 12:43:52.542 PDT run-main-0<tid=0x2b> INFO snappystore: Partitioned Region /__IDENTITYREGION2 is born with prId=1 ident:#__IDENTITYREGION2
17/05/11 12:43:52.831 PDT run-main-0<tid=0x2b> INFO snappystore: acquired dd read lock during post create
17/05/11 12:43:54.205 PDT run-main-0<tid=0x2b> INFO snappystore: FabricDatabase: waiting for index loading from GFXD-DEFAULT-DISKSTORE
17/05/11 12:43:54.205 PDT run-main-0<tid=0x2b> INFO snappystore: FabricDatabase: Index loading completed for GFXD-DEFAULT-DISKSTORE in 0 ms
17/05/11 12:43:54.208 PDT Idle OplogCompactor<tid=0x83> INFO snappystore: Oplog::recoverValuesIfNeeded: recovering values from oplog#1
17/05/11 12:43:54.280 PDT run-main-0<tid=0x2b> INFO snappystore: FabricDatabase: initial DDL replay completed.
17/05/11 12:43:54.280 PDT run-main-0<tid=0x2b> INFO snappystore: FabricDatabase: Authentication recheck successful.
17/05/11 12:43:54.287 PDT run-main-0<tid=0x2b> WARN snappystore: got throwable: java.lang.NoClassDefFoundError: org/apache/hadoop/hive/metastore/api/NoSuchObjectException calling shut down
java.lang.RuntimeException: java.lang.NoClassDefFoundError: org/apache/hadoop/hive/metastore/api/NoSuchObjectException
	at com.pivotal.gemfirexd.internal.engine.store.GemFireStore.initExternalCatalog(GemFireStore.java:2352)
	at com.pivotal.gemfirexd.internal.engine.db.FabricDatabase.postCreate(FabricDatabase.java:537)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection.<init>(EmbedConnection.java:658)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection30.<init>(EmbedConnection30.java:94)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection40.<init>(EmbedConnection40.java:75)
	at com.pivotal.gemfirexd.internal.jdbc.Driver40.getNewEmbedConnection(Driver40.java:95)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:351)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:219)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:195)
	at io.snappydata.jdbc.AutoloadedDriver.connect(AutoloadedDriver.java:153)
	at com.pivotal.gemfirexd.internal.engine.fabricservice.FabricServiceImpl.startImpl(FabricServiceImpl.java:279)
	at com.pivotal.gemfirexd.internal.engine.fabricservice.FabricServerImpl.start(FabricServerImpl.java:60)
	at io.snappydata.impl.ServerImpl.start(ServerImpl.scala:32)
	at io.snappydata.util.ServiceUtils$.invokeStartFabricServer(ServiceUtils.scala:70)
	at org.apache.spark.sql.SnappyContext$.invokeServices(SnappyContext.scala:1067)
	at org.apache.spark.sql.SnappyContext$.initGlobalSnappyContext(SnappyContext.scala:1031)
	at org.apache.spark.sql.SnappySession.<init>(SnappySession.scala:124)
	at org.apache.spark.sql.SnappySession.<init>(SnappySession.scala:74)
	at TimeUsage$.<init>(TimeUsage.scala:18)
	at TimeUsage$.<clinit>(TimeUsage.scala)
	at TimeUsage.main(TimeUsage.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sbt.Run.invokeMain(Run.scala:67)
	at sbt.Run.run0(Run.scala:61)
	at sbt.Run.sbt$Run$$execute$1(Run.scala:51)
	at sbt.Run$$anonfun$run$1.apply$mcV$sp(Run.scala:55)
	at sbt.Run$$anonfun$run$1.apply(Run.scala:55)
	at sbt.Run$$anonfun$run$1.apply(Run.scala:55)
	at sbt.Logger$$anon$4.apply(Logger.scala:85)
	at sbt.TrapExit$App.run(TrapExit.scala:248)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoClassDefFoundError: org/apache/hadoop/hive/metastore/api/NoSuchObjectException
	at io.snappydata.impl.SnappyHiveCatalog.getHMSQuery(SnappyHiveCatalog.java:155)
	at io.snappydata.impl.SnappyHiveCatalog.<init>(SnappyHiveCatalog.java:82)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at java.lang.Class.newInstance(Class.java:442)
	at com.pivotal.gemfirexd.internal.engine.store.GemFireStore.initExternalCatalog(GemFireStore.java:2338)
	... 33 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.metastore.api.NoSuchObjectException
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 41 more
17/05/11 12:43:54.290 PDT run-main-0<tid=0x2b> INFO snappystore: Stopping GemFireXD Management/Monitoring ... 
17/05/11 12:43:54.290 PDT run-main-0<tid=0x2b> INFO snappystore: Unregistered GemFireXD MBeans: []
17/05/11 12:43:54.291 PDT run-main-0<tid=0x2b> INFO snappystore: GfxdHeapThreshold: Stopping Query Cancellation Thread
17/05/11 12:43:54.291 PDT gemfirexd.QueryCanceller<tid=0x7f> INFO snappystore: GfxdHeapThreshold: Processing CRITICAL_UP event
17/05/11 12:43:54.291 PDT gemfirexd.QueryCanceller<tid=0x7f> INFO snappystore: GfxdHeapThreshold: Query Cancellation Thread Stopped 
17/05/11 12:43:54.292 PDT run-main-0<tid=0x2b> INFO snappystore: Disconnecting GemFire distributed system and stopping GemFireStore
17/05/11 12:43:54.301 PDT run-main-0<tid=0x2b> INFO snappystore: GemFireCache[id = 1926926596; isClosing = true; isShutDownAll = false; closingGatewayHubsByShutdownAll = false; created = Thu May 11 12:43:50 PDT 2017; server = false; copyOnRead = false; lockLease = 120; lockTimeout = 60]: Now closing.
17/05/11 12:43:54.318 PDT run-main-0<tid=0x2b> INFO snappystore: closing DiskStore[GFXD-DEFAULT-DISKSTORE]
17/05/11 12:43:54.320 PDT run-main-0<tid=0x2b> INFO snappystore: Unlocked disk store GFXD-DEFAULT-DISKSTORE
17/05/11 12:43:54.320 PDT run-main-0<tid=0x2b> INFO snappystore: Stopping DiskStoreTaskPool
17/05/11 12:43:54.320 PDT run-main-0<tid=0x2b> INFO snappystore: closing DiskStore[GFXD-DD-DISKSTORE]
17/05/11 12:43:54.320 PDT run-main-0<tid=0x2b> INFO snappystore: Unlocked disk store GFXD-DD-DISKSTORE
17/05/11 12:43:54.321 PDT run-main-0<tid=0x2b> INFO snappystore: Stopping DiskStoreTaskPool
17/05/11 12:43:55.435 PDT run-main-0<tid=0x2b> INFO snappystore: TraceFabricServiceBoot: GemFireStore service stopped successfully, notifying status ... 
17/05/11 12:43:55.442 PDT run-main-0<tid=0x2b> INFO snappystore: 
[TRACE 2017/05/11 12:43:55.438 PDT GFXD:TRACE <run-main-0> tid=0x2b] (XID = 2(UserTransaction)@18bb6ff2;txState=null;supportsTX=true), (SESSIONID = 1), (DATABASE = snappydata), (DRDAID = null), Failed Statement is: null
ERROR XJ040: Failed to start database 'gemfirexd', see the cause for details.
	at com.pivotal.gemfirexd.internal.iapi.error.StandardException.newException(StandardException.java:473)
	at com.pivotal.gemfirexd.internal.engine.db.FabricDatabase.postCreate(FabricDatabase.java:585)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection.<init>(EmbedConnection.java:658)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection30.<init>(EmbedConnection30.java:94)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection40.<init>(EmbedConnection40.java:75)
	at com.pivotal.gemfirexd.internal.jdbc.Driver40.getNewEmbedConnection(Driver40.java:95)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:351)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:219)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:195)
	at io.snappydata.jdbc.AutoloadedDriver.connect(AutoloadedDriver.java:153)
	at com.pivotal.gemfirexd.internal.engine.fabricservice.FabricServiceImpl.startImpl(FabricServiceImpl.java:279)
	at com.pivotal.gemfirexd.internal.engine.fabricservice.FabricServerImpl.start(FabricServerImpl.java:60)
	at io.snappydata.impl.ServerImpl.start(ServerImpl.scala:32)
	at io.snappydata.util.ServiceUtils$.invokeStartFabricServer(ServiceUtils.scala:70)
	at org.apache.spark.sql.SnappyContext$.invokeServices(SnappyContext.scala:1067)
	at org.apache.spark.sql.SnappyContext$.initGlobalSnappyContext(SnappyContext.scala:1031)
	at org.apache.spark.sql.SnappySession.<init>(SnappySession.scala:124)
	at org.apache.spark.sql.SnappySession.<init>(SnappySession.scala:74)
	at TimeUsage$.<init>(TimeUsage.scala:18)
	at TimeUsage$.<clinit>(TimeUsage.scala)
	at TimeUsage.main(TimeUsage.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sbt.Run.invokeMain(Run.scala:67)
	at sbt.Run.run0(Run.scala:61)
	at sbt.Run.sbt$Run$$execute$1(Run.scala:51)
	at sbt.Run$$anonfun$run$1.apply$mcV$sp(Run.scala:55)
	at sbt.Run$$anonfun$run$1.apply(Run.scala:55)
	at sbt.Run$$anonfun$run$1.apply(Run.scala:55)
	at sbt.Logger$$anon$4.apply(Logger.scala:85)
	at sbt.TrapExit$App.run(TrapExit.scala:248)
	at java.lang.Thread.run(Thread.java:745)
============= begin nested exception, level (1) ===========
java.lang.RuntimeException: java.lang.NoClassDefFoundError: org/apache/hadoop/hive/metastore/api/NoSuchObjectException
	at com.pivotal.gemfirexd.internal.engine.store.GemFireStore.initExternalCatalog(GemFireStore.java:2352)
	at com.pivotal.gemfirexd.internal.engine.db.FabricDatabase.postCreate(FabricDatabase.java:537)
	... 32 more
============= end nested exception, level (1) ===========
============= begin nested exception, level (2) ===========
java.lang.NoClassDefFoundError: org/apache/hadoop/hive/metastore/api/NoSuchObjectException
	at io.snappydata.impl.SnappyHiveCatalog.getHMSQuery(SnappyHiveCatalog.java:155)
	at io.snappydata.impl.SnappyHiveCatalog.<init>(SnappyHiveCatalog.java:82)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at java.lang.Class.newInstance(Class.java:442)
	at com.pivotal.gemfirexd.internal.engine.store.GemFireStore.initExternalCatalog(GemFireStore.java:2338)
	... 33 more
============= end nested exception, level (2) ===========
============= begin nested exception, level (3) ===========
java.lang.ClassNotFoundException: org.apache.hadoop.hive.metastore.api.NoSuchObjectException
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 41 more
============= end nested exception, level (3) ===========

17/05/11 12:43:55.443 PDT run-main-0<tid=0x2b> INFO snappystore: ERROR XJ040: Failed to start database 'gemfirexd', see the cause for details.
	at com.pivotal.gemfirexd.internal.iapi.error.StandardException.newException(StandardException.java:473)
	at com.pivotal.gemfirexd.internal.engine.db.FabricDatabase.postCreate(FabricDatabase.java:585)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection.<init>(EmbedConnection.java:658)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection30.<init>(EmbedConnection30.java:94)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection40.<init>(EmbedConnection40.java:75)
	at com.pivotal.gemfirexd.internal.jdbc.Driver40.getNewEmbedConnection(Driver40.java:95)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:351)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:219)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:195)
	at io.snappydata.jdbc.AutoloadedDriver.connect(AutoloadedDriver.java:153)
	at com.pivotal.gemfirexd.internal.engine.fabricservice.FabricServiceImpl.startImpl(FabricServiceImpl.java:279)
	at com.pivotal.gemfirexd.internal.engine.fabricservice.FabricServerImpl.start(FabricServerImpl.java:60)
	at io.snappydata.impl.ServerImpl.start(ServerImpl.scala:32)
	at io.snappydata.util.ServiceUtils$.invokeStartFabricServer(ServiceUtils.scala:70)
	at org.apache.spark.sql.SnappyContext$.invokeServices(SnappyContext.scala:1067)
	at org.apache.spark.sql.SnappyContext$.initGlobalSnappyContext(SnappyContext.scala:1031)
	at org.apache.spark.sql.SnappySession.<init>(SnappySession.scala:124)
	at org.apache.spark.sql.SnappySession.<init>(SnappySession.scala:74)
	at TimeUsage$.<init>(TimeUsage.scala:18)
	at TimeUsage$.<clinit>(TimeUsage.scala)
	at TimeUsage.main(TimeUsage.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sbt.Run.invokeMain(Run.scala:67)
	at sbt.Run.run0(Run.scala:61)
	at sbt.Run.sbt$Run$$execute$1(Run.scala:51)
	at sbt.Run$$anonfun$run$1.apply$mcV$sp(Run.scala:55)
	at sbt.Run$$anonfun$run$1.apply(Run.scala:55)
	at sbt.Run$$anonfun$run$1.apply(Run.scala:55)
	at sbt.Logger$$anon$4.apply(Logger.scala:85)
	at sbt.TrapExit$App.run(TrapExit.scala:248)
	at java.lang.Thread.run(Thread.java:745)
============= begin nested exception, level (1) ===========
java.lang.RuntimeException: java.lang.NoClassDefFoundError: org/apache/hadoop/hive/metastore/api/NoSuchObjectException
	at com.pivotal.gemfirexd.internal.engine.store.GemFireStore.initExternalCatalog(GemFireStore.java:2352)
	at com.pivotal.gemfirexd.internal.engine.db.FabricDatabase.postCreate(FabricDatabase.java:537)
	... 32 more
============= end nested exception, level (1) ===========
============= begin nested exception, level (2) ===========
java.lang.NoClassDefFoundError: org/apache/hadoop/hive/metastore/api/NoSuchObjectException
	at io.snappydata.impl.SnappyHiveCatalog.getHMSQuery(SnappyHiveCatalog.java:155)
	at io.snappydata.impl.SnappyHiveCatalog.<init>(SnappyHiveCatalog.java:82)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at java.lang.Class.newInstance(Class.java:442)
	at com.pivotal.gemfirexd.internal.engine.store.GemFireStore.initExternalCatalog(GemFireStore.java:2338)
	... 33 more
============= end nested exception, level (2) ===========
============= begin nested exception, level (3) ===========
java.lang.ClassNotFoundException: org.apache.hadoop.hive.metastore.api.NoSuchObjectException
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 41 more
============= end nested exception, level (3) ===========

17/05/11 12:43:55.455 PDT Spark Context Cleaner<tid=0x> ERROR ContextCleaner: Error in cleaning thread
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply$mcV$sp(ContextCleaner.scala:177)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1305)
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:174)
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:68)
17/05/11 12:43:55.460 PDT SparkListenerBus<tid=0x> ERROR Utils: uncaught error in thread SparkListenerBus, stopping SparkContext
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:998)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
	at java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
	at org.apache.spark.scheduler.LiveListenerBus$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(LiveListenerBus.scala:80)
	at org.apache.spark.scheduler.LiveListenerBus$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(LiveListenerBus.scala:79)
	at org.apache.spark.scheduler.LiveListenerBus$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(LiveListenerBus.scala:79)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.LiveListenerBus$$anon$1$$anonfun$run$1.apply$mcV$sp(LiveListenerBus.scala:78)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1305)
	at org.apache.spark.scheduler.LiveListenerBus$$anon$1.run(LiveListenerBus.scala:77)
17/05/11 12:43:55.469 PDT SparkListenerBus<tid=0x> INFO ServerConnector: Stopped ServerConnector@104bb17{HTTP/1.1}{0.0.0.0:4040}
17/05/11 12:43:55.472 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@5365b571{/stages/stage/kill,null,UNAVAILABLE}
17/05/11 12:43:55.472 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@64586c91{/api,null,UNAVAILABLE}
17/05/11 12:43:55.472 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@6e5ddcd7{/static,null,UNAVAILABLE}
17/05/11 12:43:55.473 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@575bfcfd{/executors/threadDump/json,null,UNAVAILABLE}
17/05/11 12:43:55.473 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@877efa4{/executors/threadDump,null,UNAVAILABLE}
17/05/11 12:43:55.473 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@7cdeda2f{/executors/json,null,UNAVAILABLE}
17/05/11 12:43:55.473 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@301125c4{/executors,null,UNAVAILABLE}
17/05/11 12:43:55.474 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@d7a4126{/environment/json,null,UNAVAILABLE}
17/05/11 12:43:55.474 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@62a2cfe7{/environment,null,UNAVAILABLE}
17/05/11 12:43:55.474 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@77177283{/Spark Cache/rdd/json,null,UNAVAILABLE}
17/05/11 12:43:55.475 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@57cd536e{/Spark Cache/rdd,null,UNAVAILABLE}
17/05/11 12:43:55.475 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@1a9eb520{/Spark Cache/json,null,UNAVAILABLE}
17/05/11 12:43:55.475 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@5078ab05{/Spark Cache,null,UNAVAILABLE}
17/05/11 12:43:55.475 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@23b07945{/stages/pool/json,null,UNAVAILABLE}
17/05/11 12:43:55.475 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@4341cbe6{/stages/pool,null,UNAVAILABLE}
17/05/11 12:43:55.476 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@be82892{/stages/stage/json,null,UNAVAILABLE}
17/05/11 12:43:55.476 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@7e11b55b{/stages/stage,null,UNAVAILABLE}
17/05/11 12:43:55.476 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@11ce2be0{/stages/json,null,UNAVAILABLE}
17/05/11 12:43:55.476 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@279530a{/stages,null,UNAVAILABLE}
17/05/11 12:43:55.477 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@3038a685{/jobs/job/json,null,UNAVAILABLE}
17/05/11 12:43:55.477 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@61d1dc2e{/jobs/job,null,UNAVAILABLE}
17/05/11 12:43:55.477 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@b0304e9{/jobs/json,null,UNAVAILABLE}
17/05/11 12:43:55.477 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@8f74088{/jobs,null,UNAVAILABLE}
17/05/11 12:43:55.479 PDT SparkListenerBus<tid=0x> INFO SparkUI: Stopped Spark web UI at http://10.1.10.186:4040
17/05/11 12:43:55.489 PDT Thread-2<tid=0x> INFO DiskBlockManager: Shutdown hook called
17/05/11 12:43:55.491 PDT Thread-2<tid=0x> INFO ShutdownHookManager: Shutdown hook called
17/05/11 12:43:55.491 PDT Thread-2<tid=0x> INFO ShutdownHookManager: Deleting directory /private/var/folders/w1/v_m_9hp567qdv77k1rrglw_c0000gn/T/spark-91fe3345-b523-457b-a9ac-c9db9564f3e7
17/05/11 12:43:55.492 PDT Thread-2<tid=0x> INFO ShutdownHookManager: Deleting directory /private/var/folders/w1/v_m_9hp567qdv77k1rrglw_c0000gn/T/spark-91fe3345-b523-457b-a9ac-c9db9564f3e7/userFiles-1d943364-720a-457d-ae2a-dff6072dc913
