17/05/11 12:40:08.739 PDT run-main-0<tid=0x2a> INFO snappystore: 
---------------------------------------------------------------------------

  Copyright (c) 2016 SnappyData, Inc. All rights reserved.

  Licensed under the Apache License, Version 2.0 (the "License"); you
  may not use this file except in compliance with the License. You
  may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
  implied. See the License for the specific language governing
  permissions and limitations under the License. See accompanying
  LICENSE file.

---------------------------------------------------------------------------
Java version:   1.5.4 amogh 031017 2017-03-10 17:51:17 +0530 javac 1.8.0_66
Native version: gemfirexd native code unavailable
Source revision: 392bbf24c28530a624b81e1f95232b6da6688e53
Source repository: branch-1.5.4
Running on: Pierces-MacBook-Pro.local/10.1.10.186, 8 cpu(s), x86_64 Mac OS X 10.11.2
Process ID: 42943
User: plamb
Current dir: /Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics
Home dir: /Users/plamb
Command Line Parameters:
  -Xms1024m
  -Xmx1024m
  -XX:ReservedCodeCacheSize=128m
  -XX:MaxMetaspaceSize=256m
Class Path:
  /usr/local/Cellar/sbt/0.13.9/libexec/sbt-launch.jar
Library Path:
  /Users/plamb/Library/Java/Extensions
  /Library/Java/Extensions
  /Network/Library/Java/Extensions
  /System/Library/Java/Extensions
  /usr/lib/java
  .
System Properties:
    awt.toolkit = sun.lwawt.macosx.LWCToolkit
    file.encoding = UTF-8
    file.encoding.pkg = sun.io
    file.separator = /
    ftp.nonProxyHosts = local|*.local|169.254/16|*.169.254/16
    gemfire.log-file = gemfirexd-interface.log
    gemfirexd.log-file = gemfirexd-interface.log
    gopherProxySet = false
    http.nonProxyHosts = local|*.local|169.254/16|*.169.254/16
    java.awt.graphicsenv = sun.awt.CGraphicsEnvironment
    java.awt.printerjob = sun.lwawt.macosx.CPrinterJob
    java.class.version = 52.0
    java.endorsed.dirs = /Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/endorsed
    java.ext.dirs = /Users/plamb/Library/Java/Extensions:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/ext:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java
    java.home = /Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre
    java.io.tmpdir = /var/folders/w1/v_m_9hp567qdv77k1rrglw_c0000gn/T/
    java.runtime.name = Java(TM) SE Runtime Environment
    java.runtime.version = 1.8.0_72-b15
    java.specification.name = Java Platform API Specification
    java.specification.vendor = Oracle Corporation
    java.specification.version = 1.8
    java.vendor = Oracle Corporation
    java.vendor.url = http://java.oracle.com/
    java.vendor.url.bug = http://bugreport.sun.com/bugreport/
    java.version = 1.8.0_72
    java.vm.info = mixed mode
    java.vm.name = Java HotSpot(TM) 64-Bit Server VM
    java.vm.specification.name = Java Virtual Machine Specification
    java.vm.specification.vendor = Oracle Corporation
    java.vm.specification.version = 1.8
    java.vm.vendor = Oracle Corporation
    java.vm.version = 25.72-b15
    jline.esc.timeout = 0
    jline.shutdownhook = false
    jna.loaded = true
    jna.platform.library.path = /usr/lib:/usr/lib
    jnidispatch.path = /var/folders/w1/v_m_9hp567qdv77k1rrglw_c0000gn/T/jna-106748474/jna362502847450425707.tmp
    line.separator = 

    os.version = 10.11.2
    p2p.useSSL = false
    path.separator = :
    socksNonProxyHosts = local|*.local|169.254/16|*.169.254/16
    sun.arch.data.model = 64
    sun.boot.class.path = /Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/classes
    sun.boot.library.path = /Library/Java/JavaVirtualMachines/jdk1.8.0_72.jdk/Contents/Home/jre/lib
    sun.cpu.endian = little
    sun.cpu.isalist = 
    sun.font.fontmanager = sun.font.CFontManager
    sun.io.unicode.encoding = UnicodeBig
    sun.java.command = /usr/local/Cellar/sbt/0.13.9/libexec/sbt-launch.jar run
    sun.java.launcher = SUN_STANDARD
    sun.jnu.encoding = UTF-8
    sun.management.compiler = HotSpot 64-Bit Tiered Compilers
    sun.nio.ch.bugLevel = 
    sun.os.patch.level = unknown
    user.country = US
    user.language = en
    user.timezone = America/Los_Angeles
---------------------------------------------------------------------------

17/05/11 12:40:08.740 PDT run-main-0<tid=0x2a> INFO snappystore: Renamed old log file to "gemfirexd-interface-01-01.log".
17/05/11 12:40:08.741 PDT run-main-0<tid=0x2a> INFO snappystore: Startup Configuration:
 ### GemFire Properties defined with system property ###
log-file=gemfirexd-interface.log
### GemFire Properties defined with api ###
mcast-port=0
### GemFire Properties using default values ###
ack-severe-alert-threshold=0
ack-wait-threshold=15
archive-disk-space-limit=0
archive-file-size-limit=0
async-distribution-timeout=0
async-max-queue-size=8
async-queue-timeout=60000
bind-address=
cache-xml-file=cache.xml
conflate-events=server
conserve-sockets=true
delta-propagation=true
deploy-working-dir=.
disable-auto-reconnect=false
disable-tcp=false
distributed-system-id=-1
durable-client-id=
durable-client-timeout=300
enable-network-partition-detection=false
enable-time-statistics=false
enforce-unique-host=false
groups=
jmx-manager=false
jmx-manager-access-file=
jmx-manager-bind-address=
jmx-manager-hostname-for-clients=
jmx-manager-http-port=7070
jmx-manager-password-file=
jmx-manager-port=1099
jmx-manager-ssl=false
jmx-manager-ssl-ciphers=any
jmx-manager-ssl-protocols=any
jmx-manager-ssl-require-authentication=true
jmx-manager-start=false
jmx-manager-update-rate=2000
locators=
lock-memory=false
log-disk-space-limit=0
log-file-size-limit=0
log-level=config
max-num-reconnect-tries=3
max-wait-time-reconnect=60000
mcast-address=239.192.81.1
mcast-flow-control=1048576, 0.25, 5000
mcast-recv-buffer-size=1048576
mcast-send-buffer-size=65535
mcast-ttl=32
member-timeout=5000
membership-port-range=1024-65535
memcached-port=0
memcached-protocol=ASCII
name=
off-heap-memory-size=
redundancy-zone=
remote-locators=
remove-unresponsive-client=false
roles=
security-=
security-client-accessor=
security-client-accessor-pp=
security-client-auth-init=
security-client-authenticator=
security-client-dhalgo=
security-log-file=
security-log-level=config
security-peer-auth-init=
security-peer-authenticator=
security-peer-verifymember-timeout=1000
server-bind-address=
socket-buffer-size=32768
socket-lease-time=60000
ssl-ciphers=any
ssl-enabled=false
ssl-protocols=any
ssl-require-authentication=true
start-locator=
statistic-archive-file=
statistic-sample-rate=1000
statistic-sampling-enabled=true
tcp-port=0
udp-fragment-size=60000
udp-recv-buffer-size=1048576
udp-send-buffer-size=65535
user-command-packages=

17/05/11 12:40:08.742 PDT run-main-0<tid=0x2a> INFO snappystore: Running in local mode since mcast-port was 0 and locators was empty.
17/05/11 12:40:08.821 PDT Thread-15 StatSampler<tid=0x76> INFO snappystore: Disabling statistic archival.
17/05/11 12:40:09.008 PDT run-main-0<tid=0x2a> INFO snappystore: Initializing region _monitoringRegion_10.1.10.186<v-1>0
17/05/11 12:40:09.071 PDT run-main-0<tid=0x2a> INFO snappystore: GemFire Cache successfully created.
17/05/11 12:40:09.078 PDT run-main-0<tid=0x2a> INFO snappystore: GfxdHeapThreshold: Query Cancellation Thread Started with query cancellation interval 100ms
17/05/11 12:40:09.094 PDT run-main-0<tid=0x2a> INFO snappystore: GemFire Cache successfully booted with 
--- file properties ---
--- EMPTY ---
--- boot connection properties ---
 gemfirexd.access="memstore"
 gemfirexd.authentication.required="false"
 gemfirexd.database-object="com.pivotal.gemfirexd.internal.engine.db.FabricDatabase@1f9b0289"
 gemfirexd.engineType="2"
 gemfirexd.serviceLocale="en_US"
 gemfirexd.serviceProtocol="com.pivotal.gemfirexd.internal.database.Database"
 mcast-port="0"
 route-query="false"
--- end --

17/05/11 12:40:09.095 PDT run-main-0<tid=0x2a> INFO snappystore: TraceFabricServiceBoot: GemFireStore: booted with persist-indexes=true
17/05/11 12:40:09.099 PDT run-main-0<tid=0x2a> INFO snappystore: This JVM is setup with SnappyData datastore role.
17/05/11 12:40:09.142 PDT run-main-0<tid=0x2a> INFO snappystore: Locked disk store GFXD-DEFAULT-DISKSTORE for exclusive access in directory: /Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/.
17/05/11 12:40:09.177 PDT run-main-0<tid=0x2a> INFO snappystore: Recovered disk store GFXD-DEFAULT-DISKSTORE with unique id 9563dc3b-a6ae-4b2a-977d-5e6abb70f5e5
17/05/11 12:40:09.185 PDT run-main-0<tid=0x2a> INFO snappystore: Recovering oplog#1 /Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./BACKUPGFXD-DEFAULT-DISKSTORE_1.drf for disk store GFXD-DEFAULT-DISKSTORE.
17/05/11 12:40:09.187 PDT run-main-0<tid=0x2a> INFO snappystore: Recovering oplog#1 /Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./BACKUPGFXD-DEFAULT-DISKSTORE_1.krf for disk store GFXD-DEFAULT-DISKSTORE.
17/05/11 12:40:09.199 PDT run-main-0<tid=0x2a> INFO snappystore: recovery oplog load took 14 ms
17/05/11 12:40:09.354 PDT run-main-0<tid=0x2a> INFO snappystore: Created oplog#2 drf for disk store GFXD-DEFAULT-DISKSTORE.
17/05/11 12:40:10.750 PDT run-main-0<tid=0x2a> INFO snappystore: Created oplog#2 crf for disk store GFXD-DEFAULT-DISKSTORE.
17/05/11 12:40:10.761 PDT run-main-0<tid=0x2a> INFO snappystore: recovery region initialization took 1,562 ms
17/05/11 12:40:10.768 PDT run-main-0<tid=0x2a> INFO snappystore: Locked disk store GFXD-DD-DISKSTORE for exclusive access in directory: ./datadictionary
17/05/11 12:40:10.772 PDT run-main-0<tid=0x2a> INFO snappystore: Recovered disk store GFXD-DD-DISKSTORE with unique id d3cdc1da-d856-4b7a-8372-42c5938100ca
17/05/11 12:40:10.773 PDT run-main-0<tid=0x2a> INFO snappystore: Recovering oplog#1 /Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./datadictionary/BACKUPGFXD-DD-DISKSTORE_1.drf for disk store GFXD-DD-DISKSTORE.
17/05/11 12:40:10.773 PDT run-main-0<tid=0x2a> INFO snappystore: Recovering oplog#1 /Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./datadictionary/BACKUPGFXD-DD-DISKSTORE_1.crf for disk store GFXD-DD-DISKSTORE.
17/05/11 12:40:10.773 PDT run-main-0<tid=0x2a> INFO snappystore: recovery oplog load took 0 ms
17/05/11 12:40:10.775 PDT Oplog Delete Task<tid=0x84> INFO snappystore: Deleted oplog#1 crf for disk store GFXD-DD-DISKSTORE.
17/05/11 12:40:10.775 PDT Oplog Delete Task<tid=0x84> INFO snappystore: Deleted oplog#1 drf for disk store GFXD-DD-DISKSTORE.
17/05/11 12:40:10.777 PDT run-main-0<tid=0x2a> INFO snappystore: Created oplog#2 drf for disk store GFXD-DD-DISKSTORE.
17/05/11 12:40:10.790 PDT run-main-0<tid=0x2a> INFO snappystore: Created oplog#2 crf for disk store GFXD-DD-DISKSTORE.
17/05/11 12:40:10.793 PDT run-main-0<tid=0x2a> INFO snappystore: recoverOplogs oplog: oplog#1 parent: GFXD-DD-DISKSTORE, needskrf: true
17/05/11 12:40:10.793 PDT run-main-0<tid=0x2a> INFO snappystore: createKrfAsync called for oplog: oplog#1, parent: GFXD-DD-DISKSTORE
17/05/11 12:40:10.794 PDT run-main-0<tid=0x2a> INFO snappystore: recovery region initialization took 20 ms
17/05/11 12:40:10.800 PDT run-main-0<tid=0x2a> WARN snappystore: Creating persistent region GFXD_PdxTypes, but enable-network-partition-detection is set to false. Running with network partition detection disabled can lead to an unrecoverable system in the event of a network split.
17/05/11 12:40:10.800 PDT run-main-0<tid=0x2a> INFO snappystore: Initializing region GFXD_PdxTypes
17/05/11 12:40:10.801 PDT run-main-0<tid=0x2a> INFO snappystore: Region /GFXD_PdxTypes recovered from the local disk. Old persistent ID: /10.1.10.186:/Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./datadictionary created at timestamp 1494525680535 version 0 diskStoreId d3cdc1da-d856-4b7a-8372-42c5938100ca name , new persistent ID /10.1.10.186:/Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./datadictionary created at timestamp 1494531610800 version 0 diskStoreId d3cdc1da-d856-4b7a-8372-42c5938100ca name 
17/05/11 12:40:10.804 PDT run-main-0<tid=0x2a> INFO snappystore: Initializing region _DDL_STMTS_META_REGION
17/05/11 12:40:10.804 PDT run-main-0<tid=0x2a> INFO snappystore: Region /_DDL_STMTS_META_REGION recovered from the local disk. Old persistent ID: /10.1.10.186:/Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./datadictionary created at timestamp 1494525680539 version 0 diskStoreId d3cdc1da-d856-4b7a-8372-42c5938100ca name , new persistent ID /10.1.10.186:/Users/plamb/Documents/SnappyData/Coding/My_Projects/SnappyBasics/./datadictionary created at timestamp 1494531610804 version 0 diskStoreId d3cdc1da-d856-4b7a-8372-42c5938100ca name 
17/05/11 12:40:10.826 PDT run-main-0<tid=0x2a> INFO snappystore: Initializing region __PR
17/05/11 12:40:10.853 PDT run-main-0<tid=0x2a> INFO snappystore: Partitioned Region /__IDENTITYREGION2 is born with prId=1 ident:#__IDENTITYREGION2
17/05/11 12:40:11.141 PDT run-main-0<tid=0x2a> INFO snappystore: acquired dd read lock during post create
17/05/11 12:40:12.465 PDT run-main-0<tid=0x2a> INFO snappystore: FabricDatabase: waiting for index loading from GFXD-DEFAULT-DISKSTORE
17/05/11 12:40:12.466 PDT run-main-0<tid=0x2a> INFO snappystore: FabricDatabase: Index loading completed for GFXD-DEFAULT-DISKSTORE in 1 ms
17/05/11 12:40:12.468 PDT Idle OplogCompactor<tid=0x82> INFO snappystore: Oplog::recoverValuesIfNeeded: recovering values from oplog#1
17/05/11 12:40:12.545 PDT run-main-0<tid=0x2a> INFO snappystore: FabricDatabase: initial DDL replay completed.
17/05/11 12:40:12.545 PDT run-main-0<tid=0x2a> INFO snappystore: FabricDatabase: Authentication recheck successful.
17/05/11 12:40:12.553 PDT run-main-0<tid=0x2a> WARN snappystore: got throwable: java.lang.NoClassDefFoundError: org/apache/hadoop/hive/metastore/api/NoSuchObjectException calling shut down
java.lang.RuntimeException: java.lang.NoClassDefFoundError: org/apache/hadoop/hive/metastore/api/NoSuchObjectException
	at com.pivotal.gemfirexd.internal.engine.store.GemFireStore.initExternalCatalog(GemFireStore.java:2352)
	at com.pivotal.gemfirexd.internal.engine.db.FabricDatabase.postCreate(FabricDatabase.java:537)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection.<init>(EmbedConnection.java:658)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection30.<init>(EmbedConnection30.java:94)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection40.<init>(EmbedConnection40.java:75)
	at com.pivotal.gemfirexd.internal.jdbc.Driver40.getNewEmbedConnection(Driver40.java:95)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:351)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:219)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:195)
	at io.snappydata.jdbc.AutoloadedDriver.connect(AutoloadedDriver.java:153)
	at com.pivotal.gemfirexd.internal.engine.fabricservice.FabricServiceImpl.startImpl(FabricServiceImpl.java:279)
	at com.pivotal.gemfirexd.internal.engine.fabricservice.FabricServerImpl.start(FabricServerImpl.java:60)
	at io.snappydata.impl.ServerImpl.start(ServerImpl.scala:32)
	at io.snappydata.util.ServiceUtils$.invokeStartFabricServer(ServiceUtils.scala:70)
	at org.apache.spark.sql.SnappyContext$.invokeServices(SnappyContext.scala:1067)
	at org.apache.spark.sql.SnappyContext$.initGlobalSnappyContext(SnappyContext.scala:1031)
	at org.apache.spark.sql.SnappySession.<init>(SnappySession.scala:124)
	at org.apache.spark.sql.SnappySession.<init>(SnappySession.scala:74)
	at TimeUsage$.<init>(TimeUsage.scala:18)
	at TimeUsage$.<clinit>(TimeUsage.scala)
	at TimeUsage.main(TimeUsage.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sbt.Run.invokeMain(Run.scala:67)
	at sbt.Run.run0(Run.scala:61)
	at sbt.Run.sbt$Run$$execute$1(Run.scala:51)
	at sbt.Run$$anonfun$run$1.apply$mcV$sp(Run.scala:55)
	at sbt.Run$$anonfun$run$1.apply(Run.scala:55)
	at sbt.Run$$anonfun$run$1.apply(Run.scala:55)
	at sbt.Logger$$anon$4.apply(Logger.scala:85)
	at sbt.TrapExit$App.run(TrapExit.scala:248)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoClassDefFoundError: org/apache/hadoop/hive/metastore/api/NoSuchObjectException
	at io.snappydata.impl.SnappyHiveCatalog.getHMSQuery(SnappyHiveCatalog.java:155)
	at io.snappydata.impl.SnappyHiveCatalog.<init>(SnappyHiveCatalog.java:82)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at java.lang.Class.newInstance(Class.java:442)
	at com.pivotal.gemfirexd.internal.engine.store.GemFireStore.initExternalCatalog(GemFireStore.java:2338)
	... 33 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.metastore.api.NoSuchObjectException
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 41 more
17/05/11 12:40:12.556 PDT run-main-0<tid=0x2a> INFO snappystore: Stopping GemFireXD Management/Monitoring ... 
17/05/11 12:40:12.557 PDT run-main-0<tid=0x2a> INFO snappystore: Unregistered GemFireXD MBeans: []
17/05/11 12:40:12.557 PDT run-main-0<tid=0x2a> INFO snappystore: GfxdHeapThreshold: Stopping Query Cancellation Thread
17/05/11 12:40:12.557 PDT gemfirexd.QueryCanceller<tid=0x7e> INFO snappystore: GfxdHeapThreshold: Processing CRITICAL_UP event
17/05/11 12:40:12.557 PDT gemfirexd.QueryCanceller<tid=0x7e> INFO snappystore: GfxdHeapThreshold: Query Cancellation Thread Stopped 
17/05/11 12:40:12.558 PDT run-main-0<tid=0x2a> INFO snappystore: Disconnecting GemFire distributed system and stopping GemFireStore
17/05/11 12:40:12.566 PDT run-main-0<tid=0x2a> INFO snappystore: GemFireCache[id = 2130474263; isClosing = true; isShutDownAll = false; closingGatewayHubsByShutdownAll = false; created = Thu May 11 12:40:08 PDT 2017; server = false; copyOnRead = false; lockLease = 120; lockTimeout = 60]: Now closing.
17/05/11 12:40:12.585 PDT run-main-0<tid=0x2a> INFO snappystore: closing DiskStore[GFXD-DEFAULT-DISKSTORE]
17/05/11 12:40:12.586 PDT run-main-0<tid=0x2a> INFO snappystore: Unlocked disk store GFXD-DEFAULT-DISKSTORE
17/05/11 12:40:12.586 PDT run-main-0<tid=0x2a> INFO snappystore: Stopping DiskStoreTaskPool
17/05/11 12:40:12.586 PDT run-main-0<tid=0x2a> INFO snappystore: closing DiskStore[GFXD-DD-DISKSTORE]
17/05/11 12:40:12.586 PDT run-main-0<tid=0x2a> INFO snappystore: Unlocked disk store GFXD-DD-DISKSTORE
17/05/11 12:40:12.587 PDT run-main-0<tid=0x2a> INFO snappystore: Stopping DiskStoreTaskPool
17/05/11 12:40:13.702 PDT run-main-0<tid=0x2a> INFO snappystore: TraceFabricServiceBoot: GemFireStore service stopped successfully, notifying status ... 
17/05/11 12:40:13.708 PDT run-main-0<tid=0x2a> INFO snappystore: 
[TRACE 2017/05/11 12:40:13.705 PDT GFXD:TRACE <run-main-0> tid=0x2a] (XID = 2(UserTransaction)@7259e9c0;txState=null;supportsTX=true), (SESSIONID = 1), (DATABASE = snappydata), (DRDAID = null), Failed Statement is: null
ERROR XJ040: Failed to start database 'gemfirexd', see the cause for details.
	at com.pivotal.gemfirexd.internal.iapi.error.StandardException.newException(StandardException.java:473)
	at com.pivotal.gemfirexd.internal.engine.db.FabricDatabase.postCreate(FabricDatabase.java:585)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection.<init>(EmbedConnection.java:658)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection30.<init>(EmbedConnection30.java:94)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection40.<init>(EmbedConnection40.java:75)
	at com.pivotal.gemfirexd.internal.jdbc.Driver40.getNewEmbedConnection(Driver40.java:95)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:351)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:219)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:195)
	at io.snappydata.jdbc.AutoloadedDriver.connect(AutoloadedDriver.java:153)
	at com.pivotal.gemfirexd.internal.engine.fabricservice.FabricServiceImpl.startImpl(FabricServiceImpl.java:279)
	at com.pivotal.gemfirexd.internal.engine.fabricservice.FabricServerImpl.start(FabricServerImpl.java:60)
	at io.snappydata.impl.ServerImpl.start(ServerImpl.scala:32)
	at io.snappydata.util.ServiceUtils$.invokeStartFabricServer(ServiceUtils.scala:70)
	at org.apache.spark.sql.SnappyContext$.invokeServices(SnappyContext.scala:1067)
	at org.apache.spark.sql.SnappyContext$.initGlobalSnappyContext(SnappyContext.scala:1031)
	at org.apache.spark.sql.SnappySession.<init>(SnappySession.scala:124)
	at org.apache.spark.sql.SnappySession.<init>(SnappySession.scala:74)
	at TimeUsage$.<init>(TimeUsage.scala:18)
	at TimeUsage$.<clinit>(TimeUsage.scala)
	at TimeUsage.main(TimeUsage.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sbt.Run.invokeMain(Run.scala:67)
	at sbt.Run.run0(Run.scala:61)
	at sbt.Run.sbt$Run$$execute$1(Run.scala:51)
	at sbt.Run$$anonfun$run$1.apply$mcV$sp(Run.scala:55)
	at sbt.Run$$anonfun$run$1.apply(Run.scala:55)
	at sbt.Run$$anonfun$run$1.apply(Run.scala:55)
	at sbt.Logger$$anon$4.apply(Logger.scala:85)
	at sbt.TrapExit$App.run(TrapExit.scala:248)
	at java.lang.Thread.run(Thread.java:745)
============= begin nested exception, level (1) ===========
java.lang.RuntimeException: java.lang.NoClassDefFoundError: org/apache/hadoop/hive/metastore/api/NoSuchObjectException
	at com.pivotal.gemfirexd.internal.engine.store.GemFireStore.initExternalCatalog(GemFireStore.java:2352)
	at com.pivotal.gemfirexd.internal.engine.db.FabricDatabase.postCreate(FabricDatabase.java:537)
	... 32 more
============= end nested exception, level (1) ===========
============= begin nested exception, level (2) ===========
java.lang.NoClassDefFoundError: org/apache/hadoop/hive/metastore/api/NoSuchObjectException
	at io.snappydata.impl.SnappyHiveCatalog.getHMSQuery(SnappyHiveCatalog.java:155)
	at io.snappydata.impl.SnappyHiveCatalog.<init>(SnappyHiveCatalog.java:82)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at java.lang.Class.newInstance(Class.java:442)
	at com.pivotal.gemfirexd.internal.engine.store.GemFireStore.initExternalCatalog(GemFireStore.java:2338)
	... 33 more
============= end nested exception, level (2) ===========
============= begin nested exception, level (3) ===========
java.lang.ClassNotFoundException: org.apache.hadoop.hive.metastore.api.NoSuchObjectException
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 41 more
============= end nested exception, level (3) ===========

17/05/11 12:40:13.709 PDT run-main-0<tid=0x2a> INFO snappystore: ERROR XJ040: Failed to start database 'gemfirexd', see the cause for details.
	at com.pivotal.gemfirexd.internal.iapi.error.StandardException.newException(StandardException.java:473)
	at com.pivotal.gemfirexd.internal.engine.db.FabricDatabase.postCreate(FabricDatabase.java:585)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection.<init>(EmbedConnection.java:658)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection30.<init>(EmbedConnection30.java:94)
	at com.pivotal.gemfirexd.internal.impl.jdbc.EmbedConnection40.<init>(EmbedConnection40.java:75)
	at com.pivotal.gemfirexd.internal.jdbc.Driver40.getNewEmbedConnection(Driver40.java:95)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:351)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:219)
	at com.pivotal.gemfirexd.internal.jdbc.InternalDriver.connect(InternalDriver.java:195)
	at io.snappydata.jdbc.AutoloadedDriver.connect(AutoloadedDriver.java:153)
	at com.pivotal.gemfirexd.internal.engine.fabricservice.FabricServiceImpl.startImpl(FabricServiceImpl.java:279)
	at com.pivotal.gemfirexd.internal.engine.fabricservice.FabricServerImpl.start(FabricServerImpl.java:60)
	at io.snappydata.impl.ServerImpl.start(ServerImpl.scala:32)
	at io.snappydata.util.ServiceUtils$.invokeStartFabricServer(ServiceUtils.scala:70)
	at org.apache.spark.sql.SnappyContext$.invokeServices(SnappyContext.scala:1067)
	at org.apache.spark.sql.SnappyContext$.initGlobalSnappyContext(SnappyContext.scala:1031)
	at org.apache.spark.sql.SnappySession.<init>(SnappySession.scala:124)
	at org.apache.spark.sql.SnappySession.<init>(SnappySession.scala:74)
	at TimeUsage$.<init>(TimeUsage.scala:18)
	at TimeUsage$.<clinit>(TimeUsage.scala)
	at TimeUsage.main(TimeUsage.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sbt.Run.invokeMain(Run.scala:67)
	at sbt.Run.run0(Run.scala:61)
	at sbt.Run.sbt$Run$$execute$1(Run.scala:51)
	at sbt.Run$$anonfun$run$1.apply$mcV$sp(Run.scala:55)
	at sbt.Run$$anonfun$run$1.apply(Run.scala:55)
	at sbt.Run$$anonfun$run$1.apply(Run.scala:55)
	at sbt.Logger$$anon$4.apply(Logger.scala:85)
	at sbt.TrapExit$App.run(TrapExit.scala:248)
	at java.lang.Thread.run(Thread.java:745)
============= begin nested exception, level (1) ===========
java.lang.RuntimeException: java.lang.NoClassDefFoundError: org/apache/hadoop/hive/metastore/api/NoSuchObjectException
	at com.pivotal.gemfirexd.internal.engine.store.GemFireStore.initExternalCatalog(GemFireStore.java:2352)
	at com.pivotal.gemfirexd.internal.engine.db.FabricDatabase.postCreate(FabricDatabase.java:537)
	... 32 more
============= end nested exception, level (1) ===========
============= begin nested exception, level (2) ===========
java.lang.NoClassDefFoundError: org/apache/hadoop/hive/metastore/api/NoSuchObjectException
	at io.snappydata.impl.SnappyHiveCatalog.getHMSQuery(SnappyHiveCatalog.java:155)
	at io.snappydata.impl.SnappyHiveCatalog.<init>(SnappyHiveCatalog.java:82)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at java.lang.Class.newInstance(Class.java:442)
	at com.pivotal.gemfirexd.internal.engine.store.GemFireStore.initExternalCatalog(GemFireStore.java:2338)
	... 33 more
============= end nested exception, level (2) ===========
============= begin nested exception, level (3) ===========
java.lang.ClassNotFoundException: org.apache.hadoop.hive.metastore.api.NoSuchObjectException
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 41 more
============= end nested exception, level (3) ===========

17/05/11 12:40:13.723 PDT Spark Context Cleaner<tid=0x> ERROR ContextCleaner: Error in cleaning thread
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply$mcV$sp(ContextCleaner.scala:177)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1305)
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:174)
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:68)
17/05/11 12:40:13.729 PDT SparkListenerBus<tid=0x> ERROR Utils: uncaught error in thread SparkListenerBus, stopping SparkContext
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:998)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
	at java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
	at org.apache.spark.scheduler.LiveListenerBus$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(LiveListenerBus.scala:80)
	at org.apache.spark.scheduler.LiveListenerBus$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(LiveListenerBus.scala:79)
	at org.apache.spark.scheduler.LiveListenerBus$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(LiveListenerBus.scala:79)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.LiveListenerBus$$anon$1$$anonfun$run$1.apply$mcV$sp(LiveListenerBus.scala:78)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1305)
	at org.apache.spark.scheduler.LiveListenerBus$$anon$1.run(LiveListenerBus.scala:77)
17/05/11 12:40:13.736 PDT SparkListenerBus<tid=0x> INFO ServerConnector: Stopped ServerConnector@667f68d4{HTTP/1.1}{0.0.0.0:4040}
17/05/11 12:40:13.738 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@7836a22d{/stages/stage/kill,null,UNAVAILABLE}
17/05/11 12:40:13.739 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@79f86a8f{/api,null,UNAVAILABLE}
17/05/11 12:40:13.739 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@153d772b{/static,null,UNAVAILABLE}
17/05/11 12:40:13.739 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@6adc3f76{/executors/threadDump/json,null,UNAVAILABLE}
17/05/11 12:40:13.740 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@584b3085{/executors/threadDump,null,UNAVAILABLE}
17/05/11 12:40:13.740 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@28d89e35{/executors/json,null,UNAVAILABLE}
17/05/11 12:40:13.740 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@7e0033dd{/executors,null,UNAVAILABLE}
17/05/11 12:40:13.740 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@496f795b{/environment/json,null,UNAVAILABLE}
17/05/11 12:40:13.741 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@526450e3{/environment,null,UNAVAILABLE}
17/05/11 12:40:13.741 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@26ee0c04{/Spark Cache/rdd/json,null,UNAVAILABLE}
17/05/11 12:40:13.741 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@1b859bb0{/Spark Cache/rdd,null,UNAVAILABLE}
17/05/11 12:40:13.741 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@6b4e0bc7{/Spark Cache/json,null,UNAVAILABLE}
17/05/11 12:40:13.741 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@26ca469c{/Spark Cache,null,UNAVAILABLE}
17/05/11 12:40:13.742 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@ac6f206{/stages/pool/json,null,UNAVAILABLE}
17/05/11 12:40:13.742 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@278ae638{/stages/pool,null,UNAVAILABLE}
17/05/11 12:40:13.742 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@1499002{/stages/stage/json,null,UNAVAILABLE}
17/05/11 12:40:13.742 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@7d4a2d57{/stages/stage,null,UNAVAILABLE}
17/05/11 12:40:13.743 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@496c81be{/stages/json,null,UNAVAILABLE}
17/05/11 12:40:13.743 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@6a799380{/stages,null,UNAVAILABLE}
17/05/11 12:40:13.743 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@4e564531{/jobs/job/json,null,UNAVAILABLE}
17/05/11 12:40:13.743 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@7d692f73{/jobs/job,null,UNAVAILABLE}
17/05/11 12:40:13.743 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@6478f9c8{/jobs/json,null,UNAVAILABLE}
17/05/11 12:40:13.743 PDT SparkListenerBus<tid=0x> INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@55ee3cbf{/jobs,null,UNAVAILABLE}
17/05/11 12:40:13.744 PDT SparkListenerBus<tid=0x> INFO SparkUI: Stopped Spark web UI at http://10.1.10.186:4040
17/05/11 12:40:13.755 PDT Thread-2<tid=0x> INFO DiskBlockManager: Shutdown hook called
17/05/11 12:40:13.757 PDT Thread-2<tid=0x> INFO ShutdownHookManager: Shutdown hook called
17/05/11 12:40:13.757 PDT Thread-2<tid=0x> INFO ShutdownHookManager: Deleting directory /private/var/folders/w1/v_m_9hp567qdv77k1rrglw_c0000gn/T/spark-d568d147-9ea7-42ae-be22-a8de3967457a/userFiles-94158edc-da2a-48d8-ae44-92b60539ff61
17/05/11 12:40:13.758 PDT Thread-2<tid=0x> INFO ShutdownHookManager: Deleting directory /private/var/folders/w1/v_m_9hp567qdv77k1rrglw_c0000gn/T/spark-d568d147-9ea7-42ae-be22-a8de3967457a
